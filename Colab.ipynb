{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "j-MGnNgHnB0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qme8AQSrcih1"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rfo6drxcsTx",
        "outputId": "324438f3-785f-428f-bfd1-c8bfe8110944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n py3918 python=3.9.18 -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpdaRddudCMM",
        "outputId": "2619ae55-aac4-425a-92fc-81b6f593de32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.1.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/py3918\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9.18\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2025.1.31-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.6.4-hb9d3cd8_0 \n",
            "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.6.4-hb9d3cd8_0 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.48.0-hee588c1_1 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.4.0-h7b32b05_1 \n",
            "  pip                conda-forge/noarch::pip-25.0-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.9.18-h0755675_1_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-75.8.0-pyhff2d567_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025a-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "  xz                 conda-forge/linux-64::xz-5.6.4-hbcc6ac9_0 \n",
            "  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.6.4-hbcc6ac9_0 \n",
            "  xz-tools           conda-forge/linux-64::xz-tools-5.6.4-hb9d3cd8_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate py3918\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate py3918"
      ],
      "metadata": {
        "id": "VEIclgTWdeMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n py3918 python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR0N7x-ldn2U",
        "outputId": "ccef2048-81af-4ac4-c10f-3e32e7b0dfaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bhargavchippada/forceatlas2.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quZ1iNamfsSI",
        "outputId": "b5b829a5-e03f-4a46-b4b0-af6d21e485b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'forceatlas2'...\n",
            "remote: Enumerating objects: 232, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 232 (delta 78), reused 74 (delta 74), pack-reused 142 (from 1)\u001b[K\n",
            "Receiving objects: 100% (232/232), 502.31 KiB | 2.15 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krXoDZoWkJsO",
        "outputId": "a3f9b6f0-1162-415a-be00-ba0dffa38695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/site-packages (3.0.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge fa2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsDTTbj9k51u",
        "outputId": "016be130-e83a-4916-b1be-5773e6689d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - fa2\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-24.11.3              |  py311h38be061_0         1.1 MB  conda-forge\n",
            "    fa2-0.3.5                  |  py311hd4cff14_2          97 KB  conda-forge\n",
            "    libblas-3.9.0              |28_h59b9bed_openblas          16 KB  conda-forge\n",
            "    libcblas-3.9.0             |28_he106b2a_openblas          16 KB  conda-forge\n",
            "    libgfortran-14.2.0         |       h69a702a_1          53 KB  conda-forge\n",
            "    libgfortran5-14.2.0        |       hd5240d6_1         1.4 MB  conda-forge\n",
            "    liblapack-3.9.0            |28_h7ac8fdf_openblas          16 KB  conda-forge\n",
            "    libopenblas-0.3.28         |pthreads_h94d23a6_1         5.3 MB  conda-forge\n",
            "    numpy-2.2.2                |  py311h5d046bc_0         8.6 MB  conda-forge\n",
            "    scipy-1.15.1               |  py311hc1ac118_0        18.3 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        35.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  fa2                conda-forge/linux-64::fa2-0.3.5-py311hd4cff14_2 \n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-28_h59b9bed_openblas \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-28_he106b2a_openblas \n",
            "  libgfortran        conda-forge/linux-64::libgfortran-14.2.0-h69a702a_1 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-14.2.0-hd5240d6_1 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-28_h7ac8fdf_openblas \n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.28-pthreads_h94d23a6_1 \n",
            "  numpy              conda-forge/linux-64::numpy-2.2.2-py311h5d046bc_0 \n",
            "  scipy              conda-forge/linux-64::scipy-1.15.1-py311hc1ac118_0 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                     2024.12.14-hbcca054_0 --> 2025.1.31-hbcca054_0 \n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "scipy-1.15.1         | 18.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "numpy-2.2.2          | 8.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libopenblas-0.3.28   | 5.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fa2-0.3.5            | 97 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran-14.2.0   | 53 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libblas-3.9.0        | 16 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblapack-3.9.0      | 16 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 16 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "scipy-1.15.1         | 18.3 MB   | :   3% 0.025555909401098365/1 [00:00<00:03,  3.97s/it]\n",
            "\n",
            "libopenblas-0.3.28   | 5.3 MB    | :  22% 0.21733677056950482/1 [00:00<00:00,  2.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | :   1% 0.01364371451460054/1 [00:00<00:11, 11.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.1         | 18.3 MB   | :  32% 0.3151895492802132/1 [00:00<00:00,  1.80it/s]  \n",
            "\n",
            "libopenblas-0.3.28   | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]                \u001b[A\u001b[A\n",
            "\n",
            "libopenblas-0.3.28   | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran-14.2.0   | 53 KB     | :  30% 0.30342426431098024/1 [00:00<00:00,  1.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran-14.2.0   | 53 KB     | : 100% 1.0/1 [00:00<00:00,  1.23it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  3.61it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libgfortran5-14.2.0  | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  3.61it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libblas-3.9.0        | 16 KB     | :  99% 0.9857409301486072/1 [00:00<00:00,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.1         | 18.3 MB   | :  61% 0.6099343710395476/1 [00:00<00:00,  2.32it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblapack-3.9.0      | 16 KB     | :  99% 0.9897903703256208/1 [00:00<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblapack-3.9.0      | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.23it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fa2-0.3.5            | 97 KB     | :  16% 0.1648140510416562/1 [00:00<00:01,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fa2-0.3.5            | 97 KB     | : 100% 1.0/1 [00:00<00:00,  1.94s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 16 KB     | :  99% 0.9906282121047222/1 [00:00<00:00,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.08it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "scipy-1.15.1         | 18.3 MB   | :  96% 0.9609021934812986/1 [00:00<00:00,  2.79it/s]\n",
            "numpy-2.2.2          | 8.6 MB    | :   2% 0.0235205150766643/1 [00:00<00:15, 16.03s/it]    \u001b[A\n",
            "scipy-1.15.1         | 18.3 MB   | : 100% 1.0/1 [00:00<00:00,  2.79it/s]               \n",
            "\n",
            "libopenblas-0.3.28   | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran-14.2.0   | 53 KB     | : 100% 1.0/1 [00:00<00:00,  1.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran-14.2.0   | 53 KB     | : 100% 1.0/1 [00:00<00:00,  1.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libblas-3.9.0        | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "conda-24.11.3        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblapack-3.9.0      | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fa2-0.3.5            | 97 KB     | : 100% 1.0/1 [00:00<00:00,  1.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fa2-0.3.5            | 97 KB     | : 100% 1.0/1 [00:00<00:00,  1.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :   9% 0.085035708354094/1 [00:00<00:07,  7.88s/it]  \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  10% 0.10493768264973302/1 [00:01<00:08,  9.05s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  14% 0.13750454967896053/1 [00:01<00:05,  6.54s/it]\u001b[A\n",
            "scipy-1.15.1         | 18.3 MB   | : 100% 1.0/1 [00:01<00:00,  2.79it/s]\n",
            "numpy-2.2.2          | 8.6 MB    | :  21% 0.2116846356899787/1 [00:01<00:03,  5.07s/it] \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  24% 0.235205150766643/1 [00:01<00:03,  5.12s/it] \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  26% 0.25691639545279465/1 [00:01<00:04,  5.47s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  28% 0.27681836974843366/1 [00:01<00:03,  5.53s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  31% 0.31300377755868647/1 [00:01<00:03,  4.47s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  34% 0.33833356302586337/1 [00:02<00:02,  4.33s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  37% 0.3745189708361161/1 [00:02<00:02,  4.36s/it] \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  42% 0.42156000098944474/1 [00:02<00:02,  3.57s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  45% 0.4523175976281596/1 [00:02<00:02,  4.34s/it] \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  51% 0.5084049797340514/1 [00:02<00:01,  3.33s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  54% 0.5427811171537915/1 [00:02<00:01,  3.97s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  58% 0.5771572545735316/1 [00:02<00:01,  3.92s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  61% 0.6133426623837844/1 [00:03<00:01,  4.18s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  66% 0.6567651517560877/1 [00:03<00:01,  3.68s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  70% 0.700187641128391/1 [00:03<00:01,  3.80s/it] \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  76% 0.7617028344058208/1 [00:03<00:00,  3.46s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  84% 0.8449292723694021/1 [00:03<00:00,  2.98s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  88% 0.8847332209606802/1 [00:03<00:00,  2.91s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | :  92% 0.9209186287709329/1 [00:04<00:00,  4.11s/it]\u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | : 100% 1.0/1 [00:04<00:00,  4.11s/it]               \u001b[A\n",
            "numpy-2.2.2          | 8.6 MB    | : 100% 1.0/1 [00:04<00:00,  5.13s/it]\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwyBmpjYgBuk",
        "outputId": "6e4212a2-4568-4ba3-f6b5-e3518269efae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scanpy in /usr/local/lib/python3.11/site-packages (1.10.4)\n",
            "Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.11/site-packages (from scanpy) (0.11.3)\n",
            "Requirement already satisfied: h5py>=3.6 in /usr/local/lib/python3.11/site-packages (from scanpy) (3.12.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from scanpy) (1.4.2)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4 in /usr/local/lib/python3.11/site-packages (from scanpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/site-packages (from scanpy) (3.10.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/site-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/site-packages (from scanpy) (3.4.2)\n",
            "Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.11/site-packages (from scanpy) (0.61.0)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/site-packages (from scanpy) (2.1.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/site-packages (from scanpy) (24.2)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/site-packages (from scanpy) (2.2.3)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.11/site-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/site-packages (from scanpy) (0.5.13)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/site-packages (from scanpy) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/site-packages (from scanpy) (1.15.1)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/site-packages (from scanpy) (0.13.2)\n",
            "Requirement already satisfied: session-info in /usr/local/lib/python3.11/site-packages (from scanpy) (1.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.11/site-packages (from scanpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.11/site-packages (from scanpy) (0.5.7)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.11/site-packages (from anndata>=0.8->scanpy) (1.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.6->scanpy) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/site-packages (from numba>=0.56->scanpy) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.5->scanpy) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=1.5->scanpy) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn>=1.1->scanpy) (3.5.0)\n",
            "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.11/site-packages (from session-info->scanpy) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->scanpy) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fa2\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Change to -1 if you want to use CPU!\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "m7WiMWMjn6Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import colorcet\n",
        "import sklearn.neighbors\n",
        "import scipy.sparse\n",
        "import umap.umap_ as umap\n",
        "from fa2 import ForceAtlas2"
      ],
      "metadata": {
        "id": "n_Mf5heJhstr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENVI\n"
      ],
      "metadata": {
        "id": "E1-qYvmmna27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(arr):\n",
        "    return(np.reshape(arr, [arr.shape[0], -1]))\n",
        "\n",
        "def force_directed_layout(affinity_matrix, cell_names=None, verbose=True, iterations=500, device='cpu'):\n",
        "    \"\"\"\" Function to compute force directed layout from the affinity_matrix\n",
        "    :param affinity_matrix: Sparse matrix representing affinities between cells\n",
        "    :param cell_names: pandas Series object with cell names\n",
        "    :param verbose: Verbosity for force directed layout computation\n",
        "    :param iterations: Number of iterations used by ForceAtlas\n",
        "    :return: Pandas data frame representing the force directed layout\n",
        "    \"\"\"\n",
        "\n",
        "    init_coords = np.random.random((affinity_matrix.shape[0], 2))\n",
        "\n",
        "    if device == 'cpu':\n",
        "        forceatlas2 = ForceAtlas2(\n",
        "            # Behavior alternatives\n",
        "            outboundAttractionDistribution=False,\n",
        "            linLogMode=False,\n",
        "            adjustSizes=False,\n",
        "            edgeWeightInfluence=1.0,\n",
        "            # Performance\n",
        "            jitterTolerance=1.0,\n",
        "            barnesHutOptimize=True,\n",
        "            barnesHutTheta=1.2,\n",
        "            multiThreaded=False,\n",
        "            # Tuning\n",
        "            scalingRatio=2.0,\n",
        "            strongGravityMode=False,\n",
        "            gravity=1.0,\n",
        "            # Log\n",
        "            verbose=verbose)\n",
        "\n",
        "        positions = forceatlas2.forceatlas2(\n",
        "            affinity_matrix, pos=init_coords, iterations=iterations)\n",
        "        positions = np.array(positions)\n",
        "\n",
        "\n",
        "    positions = pd.DataFrame(positions,\n",
        "                             index=np.arange(affinity_matrix.shape[0]), columns=['x', 'y'])\n",
        "    return positions\n",
        "\n",
        "def run_diffusion_maps(data_df, n_components=10, knn=30, alpha=0):\n",
        "    \"\"\"Run Diffusion maps using the adaptive anisotropic kernel\n",
        "    :param data_df: PCA projections of the data or adjacency matrix\n",
        "    :param n_components: Number of diffusion components\n",
        "    :param knn: Number of nearest neighbors for graph construction\n",
        "    :param alpha: Normalization parameter for the diffusion operator\n",
        "    :return: Diffusion components, corresponding eigen values and the diffusion operator\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine the kernel\n",
        "    N = data_df.shape[0]\n",
        "\n",
        "    if(type(data_df).__module__ == np.__name__):\n",
        "        data_df = pd.DataFrame(data_df)\n",
        "\n",
        "    if not scipy.sparse.issparse(data_df):\n",
        "        print(\"Determing nearest neighbor graph...\")\n",
        "        temp = sc.AnnData(data_df.values)\n",
        "        sc.pp.neighbors(temp, n_pcs=0, n_neighbors=knn)\n",
        "        kNN = temp.obsp['distances']\n",
        "\n",
        "        # Adaptive k\n",
        "        adaptive_k = int(np.floor(knn / 3))\n",
        "        adaptive_std = np.zeros(N)\n",
        "\n",
        "        for i in np.arange(len(adaptive_std)):\n",
        "            adaptive_std[i] = np.sort(kNN.data[kNN.indptr[i] : kNN.indptr[i + 1]])[\n",
        "                adaptive_k - 1\n",
        "            ]\n",
        "\n",
        "        # Kernel\n",
        "        x, y, dists = scipy.sparse.find(kNN)\n",
        "\n",
        "        # X, y specific stds\n",
        "        dists = dists / adaptive_std[x]\n",
        "        W = scipy.sparse.csr_matrix((np.exp(-dists), (x, y)), shape=[N, N])\n",
        "\n",
        "        # Diffusion components\n",
        "        kernel = W + W.T\n",
        "    else:\n",
        "        kernel = data_df\n",
        "\n",
        "    # Markov\n",
        "    D = np.ravel(kernel.sum(axis=1))\n",
        "\n",
        "    if alpha > 0:\n",
        "        # L_alpha\n",
        "        D[D != 0] = D[D != 0] ** (-alpha)\n",
        "        mat = scipy.sparse.csr_matrix((D, (range(N), range(N))), shape=[N, N])\n",
        "        kernel = mat.dot(kernel).dot(mat)\n",
        "        D = np.ravel(kernel.sum(axis=1))\n",
        "\n",
        "    D[D != 0] = 1 / D[D != 0]\n",
        "    T = scipy.sparse.csr_matrix((D, (range(N), range(N))), shape=[N, N]).dot(kernel)\n",
        "    # Eigen value dcomposition\n",
        "    D, V = scipy.sparse.linalg.eigs(T, n_components, tol=1e-4, maxiter=1000)\n",
        "    D = np.real(D)\n",
        "    V = np.real(V)\n",
        "    inds = np.argsort(D)[::-1]\n",
        "    D = D[inds]\n",
        "    V = V[:, inds]\n",
        "\n",
        "    # Normalize\n",
        "    for i in range(V.shape[1]):\n",
        "        V[:, i] = V[:, i] / np.linalg.norm(V[:, i])\n",
        "\n",
        "    # Create are results dictionary\n",
        "    res = {\"T\": T, \"EigenVectors\": V, \"EigenValues\": D}\n",
        "    res[\"EigenVectors\"] = pd.DataFrame(res[\"EigenVectors\"])\n",
        "    if not scipy.sparse.issparse(data_df):\n",
        "        res[\"EigenVectors\"].index = data_df.index\n",
        "    res[\"EigenValues\"] = pd.Series(res[\"EigenValues\"])\n",
        "    res[\"kernel\"] = kernel\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def FDL(data, k = 30):\n",
        "\n",
        "\n",
        "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=int(k), metric='euclidean',\n",
        "                               n_jobs=5).fit(data)\n",
        "    kNN = nbrs.kneighbors_graph(data, mode='distance')\n",
        "    # Adaptive k\n",
        "\n",
        "    adaptive_k = int(np.floor(k / 3))\n",
        "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=int(adaptive_k),\n",
        "                           metric='euclidean', n_jobs=5).fit(data)\n",
        "    adaptive_std = nbrs.kneighbors_graph(data, mode='distance').max(axis=1)\n",
        "    adaptive_std = np.ravel(adaptive_std.todense())\n",
        "    # Kernel\n",
        "    x, y, dists = scipy.sparse.find(kNN)\n",
        "    # X, y specific stds\n",
        "    dists = dists / adaptive_std[x]\n",
        "    N = data.shape[0]\n",
        "    W = scipy.sparse.csr_matrix((np.exp(-dists), (x, y)), shape=[N, N])\n",
        "    # Diffusion components\n",
        "    kernel = W + W.T\n",
        "    layout = force_directed_layout(kernel)\n",
        "    return(layout)"
      ],
      "metadata": {
        "id": "aLCSRfTRng_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc_data = sc.read_h5ad('/Users/anushka/Desktop/MERFISH data/sc_data.h5ad')"
      ],
      "metadata": {
        "id": "0rQzHnnSoces"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_data= sc.read_h5ad('/Users/anushka/Desktop/MERFISH data/st_data.h5ad')"
      ],
      "metadata": {
        "id": "u4FN9O-kohpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "sns.scatterplot(x = st_data.obsm['spatial'][st_data.obs['batch'] == 'mouse1_slice10'][:, 1],\n",
        "                y = -st_data.obsm['spatial'][st_data.obs['batch'] == 'mouse1_slice10'][:, 0], legend = True,\n",
        "                hue = st_data.obs['cell_type'][st_data.obs['batch'] == 'mouse1_slice10'],\n",
        "                s = 12, palette = cell_type_palette)\n",
        "plt.axis('equal')\n",
        "plt.axis('off')\n",
        "plt.title(\"MERFISH Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ujMvzUE1olgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = umap.UMAP(\n",
        "    n_neighbors = 100,\n",
        "    min_dist = 0.8,\n",
        "    n_components = 2,\n",
        ")\n",
        "\n",
        "sc_data.layers['log'] = np.log(sc_data.X + 1)\n",
        "sc.pp.highly_variable_genes(sc_data, layer = 'log', n_top_genes = 2048)\n",
        "sc_data.obsm['UMAP_exp'] = fit.fit_transform(np.log(sc_data[:, sc_data.var['highly_variable']].X + 1))"
      ],
      "metadata": {
        "id": "KHHu-xj6pVIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (10,10))\n",
        "sns.scatterplot(x = sc_data.obsm['UMAP_exp'][:, 0], y = sc_data.obsm['UMAP_exp'][:, 1],  hue = sc_data.obs['cell_type'], s = 16,\n",
        "                palette = cell_type_palette, legend = True)\n",
        "plt.tight_layout()\n",
        "plt.axis('off')\n",
        "plt.title('scRNA-seq Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k-Qdnpdppz5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scenvi\n",
        "envi_model = scenvi.ENVI(spatial_data = st_data, sc_data = sc_data)"
      ],
      "metadata": {
        "id": "Pap-Jj_rp-eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "envi_model.train()\n",
        "envi_model.impute_genes()\n",
        "envi_model.infer_niche_covet()\n",
        "envi_model.infer_niche_celltype()"
      ],
      "metadata": {
        "id": "24k39burqLQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_data.obsm['envi_latent'] = envi_model.spatial_data.obsm['envi_latent']\n",
        "st_data.obsm['COVET'] = envi_model.spatial_data.obsm['COVET']\n",
        "st_data.obsm['COVET_SQRT'] = envi_model.spatial_data.obsm['COVET_SQRT']\n",
        "st_data.uns['COVET_genes'] =  envi_model.CovGenes\n",
        "st_data.obsm['imputation'] = envi_model.spatial_data.obsm['imputation']\n",
        "st_data.obsm['cell_type_niche'] = envi_model.spatial_data.obsm['cell_type_niche']\n",
        "\n",
        "sc_data.obsm['envi_latent'] = envi_model.sc_data.obsm['envi_latent']\n",
        "sc_data.obsm['COVET'] = envi_model.sc_data.obsm['COVET']\n",
        "sc_data.obsm['COVET_SQRT'] = envi_model.sc_data.obsm['COVET_SQRT']\n",
        "sc_data.obsm['cell_type_niche'] = envi_model.sc_data.obsm['cell_type_niche']\n",
        "sc_data.uns['COVET_genes'] =  envi_model.CovGenes"
      ],
      "metadata": {
        "id": "lK8_ESqGqL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = umap.UMAP(\n",
        "    n_neighbors = 100,\n",
        "    min_dist = 0.3,\n",
        "    n_components = 2,\n",
        ")\n",
        "\n",
        "latent_umap = fit.fit_transform(np.concatenate([st_data.obsm['envi_latent'], sc_data.obsm['envi_latent']], axis = 0))\n",
        "\n",
        "st_data.obsm['latent_umap'] = latent_umap[:st_data.shape[0]]\n",
        "sc_data.obsm['latent_umap'] = latent_umap[st_data.shape[0]:]"
      ],
      "metadata": {
        "id": "uKQ_TfHHqRX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lim_arr = np.concatenate([st_data.obsm['latent_umap'], sc_data.obsm['latent_umap']], axis = 0)\n",
        "\n",
        "\n",
        "delta = 1\n",
        "pre = 0.1\n",
        "xmin = np.percentile(lim_arr[:, 0], pre) - delta\n",
        "xmax = np.percentile(lim_arr[:, 0], 100 - pre) + delta\n",
        "ymin = np.percentile(lim_arr[:, 1], pre) - delta\n",
        "ymax = np.percentile(lim_arr[:, 1], 100 - pre) + delta"
      ],
      "metadata": {
        "id": "MnGVWCd3qTv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (13,5))\n",
        "plt.subplot(121)\n",
        "sns.scatterplot(x = sc_data.obsm['latent_umap'][:, 0],\n",
        "                y = sc_data.obsm['latent_umap'][:, 1], hue = sc_data.obs['cell_type'], s = 8, palette = cell_type_palette,\n",
        "                legend = False)\n",
        "plt.title(\"scRNA-seq Latent\")\n",
        "plt.xlim([xmin, xmax])\n",
        "plt.ylim([ymin, ymax])\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(122)\n",
        "sns.scatterplot(x = st_data.obsm['latent_umap'][:, 0],\n",
        "                y = st_data.obsm['latent_umap'][:, 1],  hue = st_data.obs['cell_type'], s = 8, palette = cell_type_palette, legend = True)\n",
        "\n",
        "\n",
        "legend = plt.legend(title = 'Cell Type', prop={'size': 12}, fontsize = '12',  markerscale = 3, ncol = 2, bbox_to_anchor = (1, 1))#, loc = 'lower left')\n",
        "plt.setp(legend.get_title(),fontsize='12')\n",
        "plt.title(\"MERFISH Latent\")\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.xlim([xmin, xmax])\n",
        "plt.ylim([ymin, ymax])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6v13uMTYqWTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_data_sst = st_data[st_data.obs['cell_type'] == 'Sst']\n",
        "sc_data_sst = sc_data[sc_data.obs['cell_type'] == 'Sst']"
      ],
      "metadata": {
        "id": "H_JOqFkaqb52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gran_sst_palette = {'Th': (0.0, 0.294118, 0.0, 1.0),\n",
        "                    'Calb2': (0.560784, 0.478431, 0.0, 1.0),\n",
        "                    'Chodl': (1.0, 0.447059, 0.4, 1.0),\n",
        "                    'Myh8': (0.933333, 0.72549, 0.72549, 1.0),\n",
        "                    'Crhr2': (0.368627, 0.494118, 0.4, 1.0),\n",
        "                    'Hpse': (0.65098, 0.482353, 0.72549, 1.0),\n",
        "                    'Hspe': (0.352941, 0.0, 0.643137, 1.0),\n",
        "                    'Crh': (0.607843, 0.894118, 1.0, 1.0),\n",
        "                    'Pvalb Etv1': (0.92549, 0.0, 0.466667, 1.0)}"
      ],
      "metadata": {
        "id": "IfFgGRqlqlw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FDL_COVET = np.asarray(FDL(np.concatenate([flatten(st_data_sst.obsm['COVET_SQRT']),\n",
        "                                           flatten(sc_data_sst.obsm['COVET_SQRT'])], axis = 0), k = 30))\n",
        "\n",
        "st_data_sst.obsm['FDL_COVET'] = FDL_COVET[:st_data_sst.shape[0]]\n",
        "sc_data_sst.obsm['FDL_COVET'] = FDL_COVET[st_data_sst.shape[0]:]"
      ],
      "metadata": {
        "id": "kFbMO60tqqRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DC_COVET = np.asarray(run_diffusion_maps(np.concatenate([flatten(st_data_sst.obsm['COVET_SQRT']),\n",
        "                                                         flatten(sc_data_sst.obsm['COVET_SQRT'])], axis = 0), knn = 30)['EigenVectors'])[:, 1:]\n",
        "st_data_sst.obsm['DC_COVET'] = -DC_COVET[:st_data_sst.shape[0]]\n",
        "sc_data_sst.obsm['DC_COVET'] = -DC_COVET[st_data_sst.shape[0]:]"
      ],
      "metadata": {
        "id": "8xmZjhiAq09p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_data_sst.obsm['DC_COVET'] = -DC_COVET[:st_data_sst.shape[0]]\n",
        "sc_data_sst.obsm['DC_COVET'] = -DC_COVET[st_data_sst.shape[0]:]"
      ],
      "metadata": {
        "id": "sJotYIl2rGuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lim_arr = np.concatenate([st_data_sst.obsm['FDL_COVET'], sc_data_sst.obsm['FDL_COVET']], axis = 0)\n",
        "\n",
        "\n",
        "delta = 1000\n",
        "pre = 0.01\n",
        "xmin = np.percentile(lim_arr[:, 0], pre) - delta\n",
        "xmax = np.percentile(lim_arr[:, 0], 100 - pre) + delta\n",
        "ymin = np.percentile(lim_arr[:, 1], pre) - delta\n",
        "ymax = np.percentile(lim_arr[:, 1], 100 - pre) + delta"
      ],
      "metadata": {
        "id": "hjCMo1b-rJ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(121)\n",
        "sns.scatterplot(x = sc_data_sst.obsm['FDL_COVET'][:, 0],\n",
        "                y = sc_data_sst.obsm['FDL_COVET'][:, 1],\n",
        "                hue = sc_data_sst.obs['cluster_label'], s = 16,  palette= gran_sst_palette, legend = True)\n",
        "plt.tight_layout()\n",
        "plt.xlim([xmin, xmax])\n",
        "plt.ylim([ymin, ymax])\n",
        "plt.title('scRNA-seq Sst, COVET FDL')\n",
        "legend = plt.legend(title = 'Sst subtype', prop={'size': 8}, fontsize = '8',  markerscale = 1, ncol = 2)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(122)\n",
        "ax = sns.scatterplot(x = st_data_sst.obsm['FDL_COVET'][:, 0],\n",
        "                y = st_data_sst.obsm['FDL_COVET'][:, 1],\n",
        "                c = st_data_sst.obsm['DC_COVET'][:,0], s = 16,  cmap= 'cet_CET_D13', legend = False)\n",
        "plt.tight_layout()\n",
        "plt.xlim([xmin, xmax])\n",
        "plt.ylim([ymin, ymax])\n",
        "plt.axis('off')\n",
        "plt.title('MERFISH Sst, COVET FDL')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v-Mbz2G8rLAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(25,5))\n",
        "\n",
        "for ind, batch in enumerate(['mouse1_slice212', 'mouse1_slice162', 'mouse1_slice71', 'mouse2_slice270', 'mouse1_slice40']):\n",
        "    st_dataBatch = st_data[st_data.obs['batch'] == batch]\n",
        "    st_dataPlotBatch = st_data_sst[st_data_sst.obs['batch'] == batch]\n",
        "\n",
        "    plt.subplot(1,5, 1+ ind)\n",
        "    sns.scatterplot(x = st_dataBatch.obsm['spatial'][:, 0], y = st_dataBatch.obsm['spatial'][:, 1],  color = (207/255,185/255,151/255, 1))\n",
        "    sns.scatterplot(x = st_dataPlotBatch.obsm['spatial'][:, 0], y = st_dataPlotBatch.obsm['spatial'][:, 1], marker = '^',\n",
        "                        c = st_dataPlotBatch.obsm['DC_COVET'][:, 0], s = 256,  cmap= 'cet_CET_D13', legend = False)\n",
        "    plt.title(batch)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s7peg01XrVyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth_df = pd.DataFrame()\n",
        "depth_df['Subtype'] = sc_data_sst.obs['cluster_label']\n",
        "depth_df['Depth'] = -sc_data_sst.obsm['DC_COVET'][:,0]"
      ],
      "metadata": {
        "id": "ao7HX8t7rXqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subtype_depth_order = depth_df.groupby(['Subtype']).mean().sort_values(by = 'Depth', ascending=False).index\n"
      ],
      "metadata": {
        "id": "bsBDDMyprans"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "sns.set(font_scale=1.7)\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxenplot(depth_df, x = 'Subtype', y = 'Depth',# bw = 1, width = 0.9,\n",
        "          order = subtype_depth_order,\n",
        "          palette = gran_sst_palette)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iQdsWTf4rnLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subtype_canonical = pd.DataFrame([sc_data_sst[sc_data_sst.obs['cluster_label']==subtype].obsm['cell_type_niche'].mean(axis = 0) for subtype in subtype_depth_order],\n",
        "                                     index = subtype_depth_order, columns = sc_data.obsm['cell_type_niche'].columns)"
      ],
      "metadata": {
        "id": "R-_aaPf_rrUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subtype_canonical[subtype_canonical<0.2] = 0\n",
        "subtype_canonical.drop(labels=subtype_canonical.columns[(subtype_canonical == 0).all()], axis=1, inplace=True)\n",
        "subtype_canonical = subtype_canonical.div(subtype_canonical.sum(axis=1), axis=0)\n",
        "subtype_canonical.plot(kind = 'bar', stacked = 'True',\n",
        "                       color = {col:cell_type_palette[col] for col in subtype_canonical.columns})\n",
        "plt.legend(bbox_to_anchor = (1,1), ncols = 1, fontsize = 'x-small')\n",
        "plt.title(\"Predicted Niche Composition\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "plt.xlabel(\"Sst Subtype\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "npONPjxIrsri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tick_genes = np.asarray(['Adamts18','Pamr1', 'Dkkl1', 'Hs6st2', 'Slit1', 'Ighm'])\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "for ind, gene in enumerate(tick_genes):\n",
        "    plt.subplot(2,3,1+ind)\n",
        "\n",
        "    cvec = np.log(st_data[st_data.obs['batch'] == 'mouse1_slice10'].obsm['imputation'][gene] + 0.1)\n",
        "    sns.scatterplot(x = st_data.obsm['spatial'][st_data.obs['batch'] == 'mouse1_slice10'][:, 1],\n",
        "                    y = -st_data.obsm['spatial'][st_data.obs['batch'] == 'mouse1_slice10'][:, 0], legend = False,\n",
        "                    c = cvec, cmap = 'Reds',\n",
        "                    vmax = np.percentile(cvec, 95), vmin = np.percentile(cvec, 30),\n",
        "                    s = 24, edgecolor = 'k')#, palette = cell_type_palette)\n",
        "    plt.title(gene)\n",
        "    plt.axis('equal')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tb39N0FGrzx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COVET"
      ],
      "metadata": {
        "id": "YFgio-fSsAyy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c977FrirsgPy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "def calculate_covet(expression_matrix, spatial_coordinates, k=8):\n",
        "    # Find spatial nearest neighbors\n",
        "    nn = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    nn.fit(spatial_coordinates)\n",
        "    _, indices = nn.kneighbors(spatial_coordinates)\n",
        "\n",
        "    # Calculate global mean\n",
        "    global_mean = np.mean(expression_matrix, axis=0)\n",
        "\n",
        "    # Calculate COVET matrices\n",
        "    covet_matrices = []\n",
        "    for idx in indices:\n",
        "        niche_matrix = expression_matrix[idx]\n",
        "        shifted_matrix = niche_matrix - global_mean\n",
        "        covet = np.dot(shifted_matrix.T, shifted_matrix) / k\n",
        "        covet_matrices.append(covet)\n",
        "\n",
        "    return np.array(covet_matrices)\n",
        "\n",
        "\n",
        "def aot_distance(covet1, covet2, epsilon=0.1, max_iter=100):\n",
        "    \"\"\"\n",
        "    Calculate the Approximate Optimal Transport distance between two COVET matrices.\n",
        "\n",
        "    Args:\n",
        "    covet1, covet2: Input COVET matrices\n",
        "    epsilon: Regularization parameter\n",
        "    max_iter: Maximum number of iterations for Sinkhorn algorithm\n",
        "\n",
        "    Returns:\n",
        "    float: AOT distance between covet1 and covet2\n",
        "    \"\"\"\n",
        "    # Ensure matrices are positive semi-definite\n",
        "    covet1 = np.maximum(covet1, 0)\n",
        "    covet2 = np.maximum(covet2, 0)\n",
        "\n",
        "    # Calculate matrix square roots\n",
        "    sqrt_covet1 = sqrtm(covet1)\n",
        "    sqrt_covet2 = sqrtm(covet2)\n",
        "\n",
        "    # Calculate the product of square roots\n",
        "    product = np.dot(sqrt_covet1, sqrt_covet2)\n",
        "\n",
        "    # Compute the trace\n",
        "    trace_term = np.trace(covet1 + covet2 - 2 * sqrtm(product))\n",
        "\n",
        "    # Sinkhorn iteration for entropic regularization\n",
        "    n = covet1.shape[0]\n",
        "    K = np.exp(-trace_term / epsilon)\n",
        "    u = np.ones(n) / n\n",
        "    v = np.ones(n) / n\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        u = 1 / np.dot(K, v)\n",
        "        v = 1 / np.dot(K.T, u)\n",
        "\n",
        "    # Compute final distance\n",
        "    pi = np.diag(u) @ K @ np.diag(v)\n",
        "    distance = np.sum(pi * trace_term)\n",
        "\n",
        "    return np.sqrt(distance)\n",
        "\n",
        "\n",
        "\n",
        "def get_covet_knn_matrix(covet_matrices, k=8):\n",
        "    n_cells = len(covet_matrices)\n",
        "    distance_matrix = np.zeros((n_cells, n_cells))\n",
        "\n",
        "    # Calculate pairwise distances\n",
        "    for i in range(n_cells):\n",
        "        for j in range(i+1, n_cells):\n",
        "            dist = aot_distance(covet_matrices[i], covet_matrices[j])\n",
        "            distance_matrix[i, j] = distance_matrix[j, i] = dist\n",
        "\n",
        "    # Find k nearest neighbors\n",
        "    nn = NearestNeighbors(n_neighbors=k, metric='precomputed')\n",
        "    nn.fit(distance_matrix)\n",
        "\n",
        "    return nn.kneighbors(return_distance=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5I_B3DzsgPy"
      },
      "outputs": [],
      "source": [
        "expression_matrix = sc_data\n",
        "spatial_coordinates = st_data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P-vc82JsgPz"
      },
      "outputs": [],
      "source": [
        "covet_matrices = calculate_covet(expression_matrix, spatial_coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdBW_AxwsgPz"
      },
      "outputs": [],
      "source": [
        "knn_matrix = get_covet_knn_matrix(covet_matrices)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE"
      ],
      "metadata": {
        "id": "1sa8aTKLs1K_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IMI8cFLtA7N"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tensorflow.keras import layers, Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TzQWnyLtA7N"
      },
      "outputs": [],
      "source": [
        "expression_matrix = sc_data\n",
        "spatial_coordinates = st_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIX4MJKitA7N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Define the VAE model\n",
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, input_dim, latent_dim=32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(latent_dim * 2)\n",
        "        ])\n",
        "\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * 0.5) + mean\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def call(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        x_recon = self.decode(z)\n",
        "        return x_recon, mean, logvar\n",
        "\n",
        "# Define the loss function\n",
        "def vae_loss(x, x_recon, mean, logvar):\n",
        "    reconstruction_loss = tf.reduce_sum(tf.keras.losses.binary_crossentropy(x, x_recon), axis=1)\n",
        "    kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar), axis=1)\n",
        "    return tf.reduce_mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "# Training function\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        x_recon, mean, logvar = model(x)\n",
        "        loss = vae_loss(x, x_recon, mean, logvar)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "# Main training loop\n",
        "def train_vae(expression_matrix, latent_dim=32, epochs=100, batch_size=128):\n",
        "    input_dim = expression_matrix.shape[1]\n",
        "    vae = VAE(input_dim, latent_dim)\n",
        "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(expression_matrix).shuffle(1000).batch(batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in dataset:\n",
        "            loss = train_step(vae, batch, optimizer)\n",
        "            total_loss += loss\n",
        "\n",
        "        avg_loss = total_loss / len(dataset)\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    return vae\n",
        "\n",
        "# Get latent representations\n",
        "def get_latent_representations(vae, expression_matrix):\n",
        "    mean, _ = vae.encode(expression_matrix)\n",
        "    return mean.numpy()\n",
        "\n",
        "def compute_knn_matrix(latent_representations, n_neighbors=15):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
        "    nn.fit(latent_representations)\n",
        "    return nn.kneighbors_graph(mode='connectivity')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVFQ0aMEtA7O"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "vae = train_vae(expression_matrix)\n",
        "latent_representations = get_latent_representations(vae, expression_matrix)\n",
        "knn_matrix = compute_knn_matrix(latent_representations)\n",
        "\n",
        "print(\"KNN matrix shape:\", knn_matrix.shape)"
      ]
    }
  ]
}