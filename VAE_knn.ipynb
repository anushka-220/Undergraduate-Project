{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Change to -1 if you want to use CPU!\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/octopus/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import colorcet\n",
    "import sklearn.neighbors\n",
    "import scipy.sparse\n",
    "import umap.umap_ as umap\n",
    "from fa2 import ForceAtlas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_data = sc.read_h5ad('/Users/anushka/Desktop/MERFISH data/sc_data.h5ad')\n",
    "st_data= sc.read_h5ad('/Users/anushka/Desktop/MERFISH data/st_data.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_matrix = sc_data\n",
    "spatial_coordinates = st_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(latent_dim * 2)\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mean, logvar\n",
    "\n",
    "# Define the loss function\n",
    "def vae_loss(x, x_recon, mean, logvar):\n",
    "    reconstruction_loss = tf.reduce_sum(tf.keras.losses.binary_crossentropy(x, x_recon), axis=1)\n",
    "    kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar), axis=1)\n",
    "    return tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "# Training function\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_recon, mean, logvar = model(x)\n",
    "        loss = vae_loss(x, x_recon, mean, logvar)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Main training loop\n",
    "def train_vae(expression_matrix, latent_dim=32, epochs=100, batch_size=128):\n",
    "    input_dim = expression_matrix.shape[1]\n",
    "    vae = VAE(input_dim, latent_dim)\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(expression_matrix).shuffle(1000).batch(batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataset:\n",
    "            loss = train_step(vae, batch, optimizer)\n",
    "            total_loss += loss\n",
    "        \n",
    "        avg_loss = total_loss / len(dataset)\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return vae\n",
    "\n",
    "# Get latent representations\n",
    "def get_latent_representations(vae, expression_matrix):\n",
    "    mean, _ = vae.encode(expression_matrix)\n",
    "    return mean.numpy()\n",
    "\n",
    "def compute_knn_matrix(latent_representations, n_neighbors=15):\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    nn.fit(latent_representations)\n",
    "    return nn.kneighbors_graph(mode='connectivity')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "vae = train_vae(expression_matrix)\n",
    "latent_representations = get_latent_representations(vae, expression_matrix)\n",
    "knn_matrix = compute_knn_matrix(latent_representations)\n",
    "\n",
    "print(\"KNN matrix shape:\", knn_matrix.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octopus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
