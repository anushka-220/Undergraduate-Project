{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Change to -1 if you want to use CPU!\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import colorcet\n",
    "import sklearn.neighbors\n",
    "import scipy.sparse\n",
    "import umap.umap_ as umap\n",
    "from fa2 import ForceAtlas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    return(np.reshape(arr, [arr.shape[0], -1]))\n",
    "\n",
    "def force_directed_layout(affinity_matrix, cell_names=None, verbose=True, iterations=500, device='cpu'):\n",
    "    \"\"\"\" Function to compute force directed layout from the affinity_matrix\n",
    "    :param affinity_matrix: Sparse matrix representing affinities between cells\n",
    "    :param cell_names: pandas Series object with cell names\n",
    "    :param verbose: Verbosity for force directed layout computation\n",
    "    :param iterations: Number of iterations used by ForceAtlas\n",
    "    :return: Pandas data frame representing the force directed layout\n",
    "    \"\"\"\n",
    "\n",
    "    init_coords = np.random.random((affinity_matrix.shape[0], 2))\n",
    "\n",
    "    if device == 'cpu':\n",
    "        forceatlas2 = ForceAtlas2(\n",
    "            # Behavior alternatives\n",
    "            outboundAttractionDistribution=False,\n",
    "            linLogMode=False,\n",
    "            adjustSizes=False,\n",
    "            edgeWeightInfluence=1.0,\n",
    "            # Performance\n",
    "            jitterTolerance=1.0,\n",
    "            barnesHutOptimize=True,\n",
    "            barnesHutTheta=1.2,\n",
    "            multiThreaded=False,\n",
    "            # Tuning\n",
    "            scalingRatio=2.0,\n",
    "            strongGravityMode=False,\n",
    "            gravity=1.0,\n",
    "            # Log\n",
    "            verbose=verbose)\n",
    "\n",
    "        positions = forceatlas2.forceatlas2(\n",
    "            affinity_matrix, pos=init_coords, iterations=iterations)\n",
    "        positions = np.array(positions)\n",
    "\n",
    "\n",
    "    positions = pd.DataFrame(positions,\n",
    "                             index=np.arange(affinity_matrix.shape[0]), columns=['x', 'y'])\n",
    "    return positions\n",
    "\n",
    "def run_diffusion_maps(data_df, n_components=10, knn=30, alpha=0):\n",
    "    \"\"\"Run Diffusion maps using the adaptive anisotropic kernel\n",
    "    :param data_df: PCA projections of the data or adjacency matrix\n",
    "    :param n_components: Number of diffusion components\n",
    "    :param knn: Number of nearest neighbors for graph construction\n",
    "    :param alpha: Normalization parameter for the diffusion operator\n",
    "    :return: Diffusion components, corresponding eigen values and the diffusion operator\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the kernel\n",
    "    N = data_df.shape[0]\n",
    "\n",
    "    if(type(data_df).__module__ == np.__name__):\n",
    "        data_df = pd.DataFrame(data_df)\n",
    "\n",
    "    if not scipy.sparse.issparse(data_df):\n",
    "        print(\"Determing nearest neighbor graph...\")\n",
    "        temp = sc.AnnData(data_df.values)\n",
    "        sc.pp.neighbors(temp, n_pcs=0, n_neighbors=knn)\n",
    "        kNN = temp.obsp['distances']\n",
    "\n",
    "        # Adaptive k\n",
    "        adaptive_k = int(np.floor(knn / 3))\n",
    "        adaptive_std = np.zeros(N)\n",
    "\n",
    "        for i in np.arange(len(adaptive_std)):\n",
    "            adaptive_std[i] = np.sort(kNN.data[kNN.indptr[i] : kNN.indptr[i + 1]])[\n",
    "                adaptive_k - 1\n",
    "            ]\n",
    "\n",
    "        # Kernel\n",
    "        x, y, dists = scipy.sparse.find(kNN)\n",
    "\n",
    "        # X, y specific stds\n",
    "        dists = dists / adaptive_std[x]\n",
    "        W = scipy.sparse.csr_matrix((np.exp(-dists), (x, y)), shape=[N, N])\n",
    "\n",
    "        # Diffusion components\n",
    "        kernel = W + W.T\n",
    "    else:\n",
    "        kernel = data_df\n",
    "\n",
    "    # Markov\n",
    "    D = np.ravel(kernel.sum(axis=1))\n",
    "\n",
    "    if alpha > 0:\n",
    "        # L_alpha\n",
    "        D[D != 0] = D[D != 0] ** (-alpha)\n",
    "        mat = scipy.sparse.csr_matrix((D, (range(N), range(N))), shape=[N, N])\n",
    "        kernel = mat.dot(kernel).dot(mat)\n",
    "        D = np.ravel(kernel.sum(axis=1))\n",
    "\n",
    "    D[D != 0] = 1 / D[D != 0]\n",
    "    T = scipy.sparse.csr_matrix((D, (range(N), range(N))), shape=[N, N]).dot(kernel)\n",
    "    # Eigen value dcomposition\n",
    "    D, V = scipy.sparse.linalg.eigs(T, n_components, tol=1e-4, maxiter=1000)\n",
    "    D = np.real(D)\n",
    "    V = np.real(V)\n",
    "    inds = np.argsort(D)[::-1]\n",
    "    D = D[inds]\n",
    "    V = V[:, inds]\n",
    "\n",
    "    # Normalize\n",
    "    for i in range(V.shape[1]):\n",
    "        V[:, i] = V[:, i] / np.linalg.norm(V[:, i])\n",
    "\n",
    "    # Create are results dictionary\n",
    "    res = {\"T\": T, \"EigenVectors\": V, \"EigenValues\": D}\n",
    "    res[\"EigenVectors\"] = pd.DataFrame(res[\"EigenVectors\"])\n",
    "    if not scipy.sparse.issparse(data_df):\n",
    "        res[\"EigenVectors\"].index = data_df.index\n",
    "    res[\"EigenValues\"] = pd.Series(res[\"EigenValues\"])\n",
    "    res[\"kernel\"] = kernel\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def FDL(data, k = 30):\n",
    "\n",
    "\n",
    "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=int(k), metric='euclidean',\n",
    "                               n_jobs=5).fit(data)\n",
    "    kNN = nbrs.kneighbors_graph(data, mode='distance')\n",
    "    # Adaptive k\n",
    "\n",
    "    adaptive_k = int(np.floor(k / 3))\n",
    "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=int(adaptive_k),\n",
    "                           metric='euclidean', n_jobs=5).fit(data)\n",
    "    adaptive_std = nbrs.kneighbors_graph(data, mode='distance').max(axis=1)\n",
    "    adaptive_std = np.ravel(adaptive_std.todense())\n",
    "    # Kernel\n",
    "    x, y, dists = scipy.sparse.find(kNN)\n",
    "    # X, y specific stds\n",
    "    dists = dists / adaptive_std[x]\n",
    "    N = data.shape[0]\n",
    "    W = scipy.sparse.csr_matrix((np.exp(-dists), (x, y)), shape=[N, N])\n",
    "    # Diffusion components\n",
    "    kernel = W + W.T\n",
    "    layout = force_directed_layout(kernel)\n",
    "    return(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  1 8336M    1 93.4M    0     0  20881      0   4d 20h  1:18:11   4d 18h     04 16:39:35  138k7k    0     0   125k      0 18:56:17  0:00:42 18:55:35 812960   224k      0 10:33:29  0:01:04 10:32:25 1379k      0  6:16:40  0:01:08  6:15:32 2705k 0  4:26:50  0:01:19  4:25:31 1213k      0  4:21:38  0:01:20  4:20:18 1187k    0   568k      0  4:10:24  0:01:29  4:08:55  627k6k      0  4:15:39  0:01:46  4:13:53  273k     0   525k      0  4:30:39  0:01:58  4:28:41  227k     0  4:55:08  0:02:15  4:52:53  193k6:04  0:02:16  4:53:48  197k      0  5:01:38  0:02:24  4:59:14  312k   464k      0  5:06:05  0:02:30  5:03:35  338k      0  5:14:27  0:02:43  5:11:44  326k:41  0:03:16  5:54:25  126k    0     0   353k      0  6:43:00  0:03:52  6:39:08  133k.5M    0     0   351k      0  6:44:51  0:03:54  6:40:57  158k0   339k      0  6:59:25  0:04:07  6:55:18 95728   0     0   335k      0  7:03:29  0:04:11  6:59:18  150k3M    0     0   331k      0  7:09:01  0:04:17  7:04:44  155k2k      0  7:07:39  0:04:19  7:03:20  294k  333k      0  7:06:48  0:04:24  7:02:24  366k1 87.6M    0     0   332k      0  7:07:17  0:04:29  7:02:48  312k 0     0   325k      0  7:17:14  0:04:44  7:12:30  176k1.8M    0     0   320k      0  7:23:51  0:04:53  7:18:58 780866M    0     0   314k      0  7:31:58  0:05:01  7:26:57  104k  0     0  69418      0 34:58:40  0:23:31 34:35:09     0  0  69122      0 35:07:40  0:23:37 34:44:03     0M    0     0  39600      0 61:18:56  0:41:13 60:37:43     0 29056      0 83:33:59  0:56:11 82:37:48     0   0  29004      0 83:42:58  0:56:17 82:46:41     093.4M    0     0  28987      0 83:45:55  0:56:19 82:49:36     0M    0     0  22401      0   4d 12h  1:12:53   4d 11h     00   4d 14h  1:14:01   4d 12h     0.4M    0     0  22017      0   4d 14h  1:14:09   4d 13h     0 0  21987      0   4d 14h  1:14:15   4d 13h     0      0   4d 14h  1:14:18   4d 13h     0     0   4d 15h  1:15:01   4d 14h     0   4d 14h     0  4d 14h     03.4M    0     0  21574      0   4d 16h  1:15:40   4d 15h     0M    0     0  21479      0   4d 17h  1:16:01   4d 15h     0   4d 17h  1:16:05   4d 15h     0    0   4d 17h  1:16:06   4d 15h     0  0  21300      0   4d 17h  1:16:39   4d 16h     0 93.4M    0     0  21217      0   4d 18h  1:16:57   4d 17h     093.4M    0     0  21189      0   4d 18h  1:17:03   4d 17h     07      0   4d 19h  1:17:21   4d 17h     04d 19h  1:17:26   4d 17h     0   0     0  20935      0   4d 19h  1:17:59   4d 18h     0 4d 20h  1:18:00   4d 18h     0^C\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  5  571M    5 33.9M    0     0  2350k      0  0:04:09  0:00:14  0:03:55 2421k9  0:00:05  0:04:44 2425k"
     ]
    }
   ],
   "source": [
    "!curl https://dp-lab-data-public.s3.amazonaws.com/ENVI/sc_data.h5ad --output SC_Data.h5ad\n",
    "!curl https://dp-lab-data-public.s3.amazonaws.com/ENVI/st_data.h5ad --output ST_Data.h5ad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
